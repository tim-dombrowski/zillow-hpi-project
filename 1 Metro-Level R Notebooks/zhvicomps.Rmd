---
title: "Metro-Level ZHVI Comparisons"
output: html_notebook
---

## Preliminary Work: Install/Load Packages

To try and ensure that this R Notebook will run successfully, we'll use the [renv package](https://cran.r-project.org/web/packages/renv/index.html) to create a project-specific library of packages. This will allow us to install the packages that we need for this project without affecting any other projects that we may be working on. Additionally, the project library will track the specific versions of the dependency packages so that any updates to those packages will not break this project.

The code chunk below will first install the renv package if it is not already installed. Then we will load the package. Next, we'll use the `restore()` function to install any packages listed in the renv.lock file. Once these packages are installed, we can load them into the R session using the `library()` commands. Below the code chunk, we'll list out the packages that will be used in the project demo. And if you run into any trouble using renv, then you can use the second code chunk below and that should be an even more reliable approach to install the required packages.

```{r setup, results='hide', message=FALSE}
# Install renv package if not already installed
if(!"renv" %in% installed.packages()[,"Package"]) install.packages("renv")
# Load renv package
library(renv)
# Use restore() to install any packages listed in the renv.lock file
renv::restore(clean=TRUE, lockfile="../renv.lock")
# Load in the packages
library(tidyverse)
library(fst)
library(doParallel)
library(xts)
#library(urbnmapr)
```

* The [tidyverse package](https://cran.r-project.org/package=tidyverse)
* The [fst package](https://cran.r-project.org/package=fst)
* The [xts package](https://cran.r-project.org/package=xts) is short for 'eXtensible Time Series', which contains tools for working with time series data.
* The [urbnmapr package](https://github.com/UrbanInstitute/urbnmapr) has mapping data for various geographies.
  * This package is not available through the standard CRAN repository, rather through GitHub. This information is contained within the renv.lock file; however, if you wish to download manually below, the [devtools package](https://cran.r-project.org/package=devtools) contains the `install_github()` function, which can be used to install the package from GitHub.
* The [rmarkdown package](https://cran.r-project.org/package=rmarkdown) is used to generate this R Notebook.

Since the rmarkdown functionality is built into RStudio, this last one is automatically loaded when you open RStudio. So no need to use the `library()` function for it. Another observation to make about the code chunk above is that it is labeled as `setup`, which is a special name, which the R Notebook will recognize and automatically run prior to running any other code chunk. This is useful for loading in packages and setting up other global options that will be used throughout the notebook. 

Then if you wish to try and update the versions of the various R packages in the lock file, you can use the `renv::update()` function to update the packages in the project library. However, it is possible that these updates could break the code in this notebook. If so, you may need to adapt the code to work with the updated packages.

My recommendation is to first run through the code using the versions of the packages in the lock file. Then if you want to try and update the packages, you can do so and then run through the code again to see if it still works. If not, you can always revert back to the lock file versions using the `renv::restore()` function.

If you update the packages and get everything working successfully, then you can update the lock file using the `renv::snapshot()` function. This will update the lock file with the versions of the packages that are currently installed in the project library. Then you can commit the updated lock file to the repository so that others can use the updated versions of the packages.

### Alternative Package Installation Code

If you run into any trouble using renv in the code chunk above, then you can use the code chunk below to install the required packages for this analysis. This method will first check if you have already installed the packages. If any are missing, it will then install them. Then it will load the packages into the R session. A potential flaw in this approach compared to using renv is that it will simply install the latest versions of the packages, which could potentially break some of the code in this notebook if any of the updates aren't backwards compatible. 

As long as you have downloaded the entire project repository, the renv chunk above will likely be managing the packages. Thus, the `eval=FALSE` option is used to prevent this chunk from running unless manually executed. So if you only downloaded this one Rmd file, this code chunk should take care of installing the packages for you.

```{r setup2, results='hide', message=FALSE, eval=FALSE}
# Create list of packages needed for this exercise
list.of.packages = c("devtools","tidyverse","fst","xts","rmarkdown")
# Check if any have not yet been installed
new.packages = list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
# If any need to be installed, install them
if(length(new.packages)) install.packages(new.packages)
# Urban Institute Mapping package downloaded via GitHub using devtools
#library(devtools)
#install_github("UrbanInstitute/urbnmapr")
# Load in the packages
library(tidyverse)
library(fst)
library(xts)
#library(urbnmapr)
```

### Set Directories and Paths

The code chunk below sets the paths to the cleaned data files and any relevant directories.

```{r setpaths}
# Specify path to cleaned data files 
msapath = "../Data/Clean/ZHVI_clean_msa.fst"
uspath = "../Data/Clean/ZHVI_clean_country.fst"
# Create a figures directory to save any plots
figdir = "Figures/"
if (!dir.exists(figdir)) dir.create(figdir)
```

## Import Cleaned ZHVI Data

The code chunk below imports the cleaned ZHVI data from the fst files saved in importzhvi.Rmd.

```{r importdata}
# Import cleaned ZHVI data
ZHVI_MSA = read_fst(msapath)
ZHVI_US = read_fst(uspath)
```

## Housing Returns

The first step in the analysis is to transform the ZHVI data into measures of housing returns. The rationale for this step is rooted in the statistical concept of [time series stationarity](https://search.brave.com/search?q=time+series+stationarity). Check out the [Bitcoin Time Series Analysis Project](https://github.com/tim-dombrowski/bitcoin-timeseries-project) for a more detailed exploration of this concept.

### National Housing Returns

Since the country-level ZHVI data is just a single time series, we can use this as a detailed demonstration of the process to transform the ZHVI data into housing returns. 

1. The first step is to convert the ZHVI data into an xts object, using the date column as the index. 
2. Then we'll compute the monthly log returns, which is difference between the natural logarithms (`log()`) of the current month's ZHVI to the previous month's ZHVI (`lag()`). 
3. This is then multiplied by 12 to annualize the returns, and then by 100 to switch the units to percentages instead of decimals. 

This annualized housing return series is then saved to the `NATIONAL` data frame as a new variable, `AnnGrowth`.

```{r usreturns}
# Convert to xts object
usxts = xts(ZHVI_US$ZHVI,order.by=ZHVI_US$Date)
# Compute monthly log returns
usrets = log(as.numeric(usxts)) - log(as.numeric(lag(usxts)))
# Convert to annualized percentages and save to full table
ZHVI_US$AnnGrowth = usrets*12*100
```


### Metro-level Housing Returns Loop

The next code chunk will be a large one since we will be looping through each of the regions to transform the ZHVI data into annualized housing returns. Additionally, we'll estimate a market model regression for each region, where the region's housing returns are regressed on the national housing returns. The residuals from these regressions will be saved to the data frame for later analysis. Be sure to review the comments in the code for a more detailed explanation of each step.

Since there are less than 1000 MSAs, this loop shouldn't take too long to run. But it may take a few minutes depending on your machine. There is also potential for speeding up the loop on multi-core processors by working in parallel. This speed improvement of such parallelization will be demonstrated after first using a standard loop.

```{r msaloop}
# Start timer
loopt=proc.time()
# Extract unique region names
regions = levels(ZHVI_MSA$RegionName)
# Create list for storing market model results
MktModels_MSA = list()
# Loop through each MSA
#region = regions[1]
for (region in regions) {
  # Start loop timer (uncomment to use)
  # t = proc.time()
  # Identify indices for the region in full data frame
  idx = ZHVI_MSA$RegionName==region
  # Extract that subset
  regiondf = ZHVI_MSA[idx,]
  # Impute any missing observations in middle of time series
  # Below uses linear interpolation within observed time range
  regiondf$ZHVI = approxfun(1:nrow(regiondf),regiondf$ZHVI)(1:nrow(regiondf))
  # Replace missing with imputed values in main data
  ZHVI_MSA$ZHVI[idx] = regiondf$ZHVI
  # Convert to xts object
  regionxts = xts(regiondf$ZHVI,order.by=regiondf$Date)
  # Compute monthly log returns
  regionrets = log(as.numeric(regionxts)) - log(as.numeric(lag(regionxts)))
  # Convert to annualized percentages and save to full table
  ZHVI_MSA$AnnGrowth[idx] = regionrets*12*100
  # Regress the region returns on the national returns
  regionmdl = lm(ZHVI_MSA$AnnGrowth[idx]~AnnGrowth,data=ZHVI_US)
  # Add model R-squared to model output
  regionmdl$r.squared = summary(regionmdl)$r.squared
  # Save model results to MktModels_MSA list
  MktModels_MSA[[region]] = regionmdl
  # Extract model residuals to full table
  ZHVI_MSA$RegResids[idx & !is.na(ZHVI_MSA$AnnGrowth)] = MktModels_MSA[[region]]$residuals
  # Compute 12-month rolling means for smoother year-over-year values
  ZHVI_MSA$ZHVIRollMean[idx] = rollmean(regiondf$ZHVI,12,fill=NA,align="right")
  ZHVI_MSA$AnnGrowthRollMean[idx] = rollmean(ZHVI_MSA$AnnGrowth[idx],12,fill=NA,align="right")
  ZHVI_MSA$RegResidsRollMean[idx] = rollmean(ZHVI_MSA$RegResids[idx],12,fill=NA,align="right")
  # Stop loop timer and output result (uncomment to use)
  # T = proc.time() - t
  # print(paste(region, "completed in", as.character(round(T[3],2)), "seconds."))
}
# Stop timer and output result
loopT = proc.time()-loopt
print(paste("Full MSA-level Cleaning completed in", as.character(round(loopT[3],2)), "seconds."))
```



```{r}
summary(ZHVI_MSA$ZHVI)
summary(ZHVI_MSA$AnnGrowth)
summary(ZHVI_MSA$RegResids)
summary(ZHVI_MSA$ZHVIRollMean)
summary(ZHVI_MSA$AnnGrowthRollMean)
summary(ZHVI_MSA$RegResidsRollMean)
summary(MktModels_MSA) |> head()
```

#### Parallelizing the Loop

Now let's adapt the loop above to run in parallel using the `doParallel` package. This will allow the loop to run on multiple cores, which should speed up the process. The `registerDoParallel()` function is used to register the parallel backend, which will allow the `foreach()` function to run the loop in parallel. The `foreach()` function is used to run the loop in parallel, and the `%dopar%` operator is used to specify that the loop should be run in parallel. The `stopImplicitCluster()` function is used to stop the parallel backend once the loop is finished.

**Currently, this notebook is being compiled on a 12-core/24-thread CPU.**

```{r msaloopparallel}
# Start timer
loopt=proc.time()
# Extract unique region names
regions = levels(ZHVI_MSA$RegionName)
# Create list for storing market model results
#MktModels_MSA = list()
# Register parallel backend
cl = makeCluster(detectCores())
registerDoParallel(cl)
# Loop through each MSA
#region = regions[1]
MktModels_MSA = foreach(region=regions) %dopar% {
  # Start loop timer (uncomment to use)
  #t = proc.time()
  # Load xts package in iteration
  library(xts)
  # Identify indices for the region in full data frame
  idx = ZHVI_MSA$RegionName==region
  # Extract that subset
  regiondf = ZHVI_MSA[idx,]
  # Impute any missing observations in middle of time series
  # Below uses linear interpolation within observed time range
  regiondf$ZHVI = approxfun(1:nrow(regiondf),regiondf$ZHVI)(1:nrow(regiondf))
  # Replace missing with imputed values in main data
  ZHVI_MSA$ZHVI[idx] = regiondf$ZHVI
  # Convert to xts object
  regionxts = xts(regiondf$ZHVI,order.by=regiondf$Date)
  # Compute monthly log returns
 regionrets = log(as.numeric(regionxts)) - log(as.numeric(lag(regionxts)))
  # Convert to annualized percentages and save to full table
  ZHVI_MSA$AnnGrowth[idx] = regionrets*12*100
  # Regress the region returns on the national returns
  regionmdl = lm(ZHVI_MSA$AnnGrowth[idx]~AnnGrowth,data=ZHVI_US)
  # Add model R-squared to model output
  regionmdl$r.squared = summary(regionmdl)$r.squared
  # Save model results to MktModels_MSA list
  #MktModels_MSA[[region]] = regionmdl
  # Extract model residuals to full table
  ZHVI_MSA$RegResids[idx & !is.na(ZHVI_MSA$AnnGrowth)] = regionmdl$residuals
  # Compute 12-month rolling means for smoother year-over-year values
  ZHVI_MSA$ZHVIRollMean[idx] = rollmean(regiondf$ZHVI,12,fill=NA,align="right")
  ZHVI_MSA$AnnGrowthRollMean[idx] = rollmean(ZHVI_MSA$AnnGrowth[idx],12,fill=NA,align="right")
  ZHVI_MSA$RegResidsRollMean[idx] = rollmean(ZHVI_MSA$RegResids[idx],12,fill=NA,align="right")
  # Stop loop timer and output result (uncomment to use)
  # T = proc.time() - t
  # print(paste(region, "completed in", as.character(round(T[3],2)), "seconds."))
  regionmdl
  #invisible() # Invisible return to suppress output
}
# Relabel MktModels_MSA elements as region names
names(MktModels_MSA) = regions
# Stop parallel backend
stopImplicitCluster()
# Stop timer and output result
loopT = proc.time()-loopt
print(paste("Parallel MSA-level Cleaning completed in", as.character(round(loopT[3],2)), "seconds."))
```


```{r}
summary(ZHVI_MSA$ZHVI)
summary(ZHVI_MSA$AnnGrowth)
summary(ZHVI_MSA$RegResids)
summary(ZHVI_MSA$ZHVIRollMean)
summary(ZHVI_MSA$AnnGrowthRollMean)
summary(ZHVI_MSA$RegResidsRollMean)
summary(MktModels_MSA) |> head()
```

## Market Model Rankings

Let's output the top 6 and bottom 6 metros from the market models for the most recent month:

```{r msarankings1mo}
MSAnow = ZHVI_MSA[ZHVI_MSA$Date==max(ZHVI_MSA$Date),]
head(MSAnow[order(-MSAnow$RegResids),c(2,3,6,7,8,9)])
head(MSAnow[order(MSAnow$RegResids),c(2,3,6,7,8,9)])
```

Then for a longer-term comparison, let's examine the top 6 and bottom 6 of the residual rolling averages.

```{r msarankings1yr}
head(MSAnow[order(-MSAnow$RegResidsRollMean),c(2,3,6,10,11,12)])
head(MSAnow[order(MSAnow$RegResidsRollMean),c(2,3,6,10,11,12)])
```









